import tensorflow as tf


def cnn_model(config):
    model = tf.keras.models.Sequential()
    model.add(
        tf.keras.layers.Conv1D(
            filters=32,
            kernel_size=5,
            strides=1,
            padding='valid',
            data_format='channels_last',
            dilation_rate=1,
            activation=tf.keras.layers.LeakyReLU(),
            use_bias=True,
            kernel_initializer='glorot_uniform',
            bias_initializer='zeros',
            kernel_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            kernel_constraint=None,
            bias_constraint=None,
            input_shape=(config.max_doms, len(config.features))
        )
    )
    model.add(
        tf.keras.layers.BatchNormalization(
            axis=-1,
            momentum=0.99,
            epsilon=0.001,
            center=True,
            scale=True,
            beta_initializer='zeros',
            gamma_initializer='ones',
            moving_mean_initializer='zeros',
            moving_variance_initializer='ones',
            beta_regularizer=None,
            gamma_regularizer=None,
            beta_constraint=None,
            gamma_constraint=None
        )
    )
    model.add(
        tf.keras.layers.Conv1D(
            filters=64,
            kernel_size=5,
            strides=1,
            padding='valid',
            data_format='channels_last',
            dilation_rate=1,
            activation=tf.keras.layers.LeakyReLU(),
            use_bias=True,
            kernel_initializer='glorot_uniform',
            bias_initializer='zeros',
            kernel_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            kernel_constraint=None,
            bias_constraint=None
        )
    )
    model.add(
        tf.keras.layers.MaxPooling1D(
            pool_size=2,
            strides=None,
            padding='valid',
            data_format='channels_last'
        )
    )
    model.add(
        tf.keras.layers.BatchNormalization(
            axis=-1,
            momentum=0.99,
            epsilon=0.001,
            center=True,
            scale=True,
            beta_initializer='zeros',
            gamma_initializer='ones',
            moving_mean_initializer='zeros',
            moving_variance_initializer='ones',
            beta_regularizer=None,
            gamma_regularizer=None,
            beta_constraint=None,
            gamma_constraint=None
        )
    )
    model.add(
        tf.keras.layers.Conv1D(
            filters=128,
            kernel_size=5,
            strides=1,
            padding='valid',
            data_format='channels_last',
            dilation_rate=1,
            activation=tf.keras.layers.LeakyReLU(),
            use_bias=True,
            kernel_initializer='glorot_uniform',
            bias_initializer='zeros',
            kernel_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            kernel_constraint=None,
            bias_constraint=None
        )
    )
    model.add(
        tf.keras.layers.BatchNormalization(
            axis=-1,
            momentum=0.99,
            epsilon=0.001,
            center=True,
            scale=True,
            beta_initializer='zeros',
            gamma_initializer='ones',
            moving_mean_initializer='zeros',
            moving_variance_initializer='ones',
            beta_regularizer=None,
            gamma_regularizer=None,
            beta_constraint=None,
            gamma_constraint=None
        )
    )
    model.add(
        tf.keras.layers.Conv1D(
            filters=128,
            kernel_size=5,
            strides=1,
            padding='valid',
            data_format='channels_last',
            dilation_rate=1,
            activation=tf.keras.layers.LeakyReLU(),
            use_bias=True,
            kernel_initializer='glorot_uniform',
            bias_initializer='zeros',
            kernel_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            kernel_constraint=None,
            bias_constraint=None
        )
    )
    model.add(
        tf.keras.layers.MaxPooling1D(
            pool_size=2,
            strides=None,
            padding='valid',
            data_format='channels_last'
        )
    )
    model.add(
        tf.keras.layers.BatchNormalization(
            axis=-1,
            momentum=0.99,
            epsilon=0.001,
            center=True,
            scale=True,
            beta_initializer='zeros',
            gamma_initializer='ones',
            moving_mean_initializer='zeros',
            moving_variance_initializer='ones',
            beta_regularizer=None,
            gamma_regularizer=None,
            beta_constraint=None,
            gamma_constraint=None
        )
    )
    model.add(
        tf.keras.layers.Conv1D(
            filters=256,
            kernel_size=5,
            strides=1,
            padding='valid',
            data_format='channels_last',
            dilation_rate=1,
            activation=tf.keras.layers.LeakyReLU(),
            use_bias=True,
            kernel_initializer='glorot_uniform',
            bias_initializer='zeros',
            kernel_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            kernel_constraint=None,
            bias_constraint=None
        )
    )
    model.add(
        tf.keras.layers.BatchNormalization(
            axis=-1,
            momentum=0.99,
            epsilon=0.001,
            center=True,
            scale=True,
            beta_initializer='zeros',
            gamma_initializer='ones',
            moving_mean_initializer='zeros',
            moving_variance_initializer='ones',
            beta_regularizer=None,
            gamma_regularizer=None,
            beta_constraint=None,
            gamma_constraint=None
        )
    )
    model.add(
        tf.keras.layers.Conv1D(
            filters=256,
            kernel_size=5,
            strides=1,
            padding='valid',
            data_format='channels_last',
            dilation_rate=1,
            activation=tf.keras.layers.LeakyReLU(),
            use_bias=True,
            kernel_initializer='glorot_uniform',
            bias_initializer='zeros',
            kernel_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            kernel_constraint=None,
            bias_constraint=None
        )
    )
    model.add(
        tf.keras.layers.GlobalAveragePooling1D(
            data_format='channels_last'
        )
    )
    model.add(
        tf.keras.layers.Dropout(
            rate=0.5,
            noise_shape=None,
            seed=None
        )
    )
    model.add(
        tf.keras.layers.BatchNormalization(
            axis=-1,
            momentum=0.99,
            epsilon=0.001,
            center=True,
            scale=True,
            beta_initializer='zeros',
            gamma_initializer='ones',
            moving_mean_initializer='zeros',
            moving_variance_initializer='ones',
            beta_regularizer=None,
            gamma_regularizer=None,
            beta_constraint=None,
            gamma_constraint=None
        )
    )
    model.add(
        tf.keras.layers.Dense(
            units=len(config.targets),
            activation=None,
            use_bias=True,
            kernel_initializer='glorot_uniform',
            bias_initializer='zeros',
            kernel_regularizer=None,
            bias_regularizer=None,
            activity_regularizer=None,
            kernel_constraint=None,
            bias_constraint=None
        )
    )
    return model
